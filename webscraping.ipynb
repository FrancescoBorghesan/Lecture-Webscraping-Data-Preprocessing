{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping and Data Preprocessing\n",
    "\n",
    "We'll be scraping weather data from https://williamprofit.github.io/ICDSS-Lecture-Webscraping/\n",
    "\n",
    "Hopefully by the end we'll get a useful model to predict temperatures from multiple features.\n",
    "\n",
    "We'll proceed as follows:\n",
    "- Scrape website to create a dataset\n",
    "- Visualise the data\n",
    "- Preprocess the data and create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Web Scraping\n",
    "\n",
    "In order to web scrape, we start by importing all necessary libraries and setting some useful constant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # Used to parse HTML files\n",
    "import pandas as pd           # Used to store data\n",
    "from requests import get      # Used to request website HTML page\n",
    "\n",
    "# URL we'll be scraping from\n",
    "URL = 'https://williamprofit.github.io/ICDSS-Lecture-Webscraping'\n",
    "# File path to save the data to\n",
    "FILE = './data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a container to hold our data (empty for now). It contains all the features we'll be extracting and our script will fill it as we go on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the main page, we need to get the URLs of all the sub pages to scrape from. This is done by scraping the page for the links to the subpages and then visiting them in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `week_pages` holds links to all the pages containing the data, we can traverse it and scrape the sub pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save our data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now simply load our data from a file instead of web scraping again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation\n",
    "In order to create a performant model, it's important to visualise the data to get an intuition of how it could be modeled. We typically plot the predicted feature against other features and compute correlation coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting graphs\n",
    "We can start plotting graphs to visualise how the temperature evolves with different metrics. We create a list `days` which simply enumerates the days from 0 to `len(data)` which will be used for the x-axis. This can be achieved using the range function and making it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the temperature with pressure. The syntax of the plot function is as follows: `plt.plot(x-axis, y-axis, x-axis, y-axis, ..)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with temperature and wind speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now temperature and dew point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally temperature and humidity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs can now be used to visually get an intuition of how each feature relates to the one we're trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing correlation coefficients\n",
    "Graphs are useful but sometimes they can be difficult to interpret and having a standard way of determining how correlated two features are can come in quite handy. For several metrics can help, we'll be looking at the covariance. Numpy has a handy `cov` function that we'll be using. The function returns 4 values in a 2D array but we're only interested in the value at `[0][1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import cov\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a better idea of correlations between our features. The higher the covariance factor the higher the correlation. If the covariance is negative then the two features are inversely correlated. We can use all this information to decide which features to select for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing and Modelling\n",
    "\n",
    "Our data is well balanced and is not categorical so there is no need to balance, augment or one-hot-encode it. We'll only be normalising it to have it in a range of `0-1`. For that we'll use the following formula $X_{normalised}=\\frac{X-min(X)}{max(X)-min(X)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Normalise data (min-max normalisation)\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split our data into two vectors `X` and `y`. `y` contains the column we want to predict, namely the temperature. `X` contains all the columns (features) we'll use to predict the temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better evaluate our model we separate the data into a training and a testing set. The training set is fed to the model to train and the test set contains data the model has not trained on so we can compute accuracy on unseen data. To achieve this, scikit has the `train_test_split` functions which splits and shuffles the data into 4 partitions for X/y and train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally create a linear regression model using the training set and gauge the accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
