{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping and Data Preprocessing\n",
    "\n",
    "We'll be scraping weather data from https://williamprofit.github.io/ICDSS-Lecture-Webscraping/\n",
    "\n",
    "Hopefully by the end we'll get a useful model to predict temperatures from multiple features.\n",
    "\n",
    "We'll proceed as follows:\n",
    "- Scrape website to create a dataset\n",
    "- Visualise the data\n",
    "- Preprocess the data and create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Web Scraping\n",
    "\n",
    "In order to web scrape, we start by importing all necessary libraries and setting some useful constant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # Used to parse HTML files\n",
    "import pandas as pd           # Used to store data\n",
    "from requests import get      # Used to request website HTML page\n",
    "\n",
    "# URL we'll be scraping from\n",
    "URL = 'https://williamprofit.github.io/ICDSS-Lecture-Webscraping'\n",
    "# File path to save the data to\n",
    "FILE = './data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a container to hold our data (empty for now). It contains all the features we'll be extracting and our script will fill it as we go on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  'temp': [],\n",
    "  'pressure': [],\n",
    "  'wind_speed': [],\n",
    "  'dew_point': [],\n",
    "  'humidity': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the main page, we need to get the URLs of all the sub pages to scrape from. This is done by scraping the page for the links to the subpages and then visiting them in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get main page\n",
    "resp = get(URL)\n",
    "\n",
    "# Parse it using BeautifulSoup\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "# Extract the links to the week pages\n",
    "week_pages = soup.select('li > a')\n",
    "# Extract the 'href' attribute\n",
    "week_pages = list(map(lambda x: x.get('href'), week_pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `week_pages` holds links to all the pages containing the data, we can traverse it and scrape the sub pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Web scrape all week pages\n",
    "for p in week_pages:\n",
    "  url = URL + '/' + p # Append page's URL to base URL\n",
    "  print('Scraping {}'.format(url))\n",
    "\n",
    "  # Get HTML page\n",
    "  resp = get(url)\n",
    "  # Parse page\n",
    "  soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "  # Get rows and omit 1st since it contains table headers\n",
    "  rows = soup.select('tr')[1:]\n",
    "  for row in rows:\n",
    "    # Select all values from row\n",
    "    vals = row.select('th')\n",
    "    # Extract the text fields\n",
    "    vals = list(map(lambda v: v.text, vals))[1:]\n",
    "\n",
    "    # Store in data\n",
    "    data['temp'].append(vals[0])\n",
    "    data['dew_point'].append(vals[1])\n",
    "    data['humidity'].append(vals[2])\n",
    "    data['wind_speed'].append(vals[3])\n",
    "    data['pressure'].append(vals[4])\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save our data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in csv file\n",
    "print('Saving data to {}'.format(FILE))\n",
    "# Create a pandas dataframe with given feature columns\n",
    "data = pd.DataFrame(data, columns=['temp', 'pressure', 'wind_speed', 'dew_point', 'humidity'])\n",
    "# Save data to file at path FILE\n",
    "data.to_csv(FILE, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now simply load our data from a file instead of web scraping again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation\n",
    "In order to create a performant model, it's important to visualise the data to get an intuition of how it could be modeled. We typically plot the predicted feature against other features and compute correlation coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting graphs\n",
    "We can start plotting graphs to visualise how the temperature evolves with different metrics. We create a list `days` which simply enumerates the days from 0 to `len(data)` which will be used for the x-axis. This can be achieved using the range function and making it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x-axis contains days\n",
    "days = list(range(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the temperature with pressure. The syntax of the plot function is as follows: `plt.plot(x-axis, y-axis, x-axis, y-axis, ..)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('days')\n",
    "plt.ylabel('temp, pressure')\n",
    "plt.plot(days, data['temp'], days, data['pressure'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with temperature and wind speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('days')\n",
    "plt.ylabel('temp, wind_speed')\n",
    "plt.plot(days, data['temp'], days, data['wind_speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now temperature and dew point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('days')\n",
    "plt.ylabel('temp, dew_point')\n",
    "plt.plot(days, data['temp'], days, data['dew_point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally temperature and humidity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('days')\n",
    "plt.ylabel('temp, humidity')\n",
    "plt.plot(days, data['temp'], days, data['humidity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs can now be used to visually get an intuition of how each feature relates to the one we're trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing correlation coefficients\n",
    "Graphs are useful but sometimes they can be difficult to interpret and having a standard way of determining how correlated two features are can come in quite handy. For several metrics can help, we'll be looking at the covariance. Numpy has a handy `cov` function that we'll be using. The function returns 4 values in a 2D array but we're only interested in the value at `[0][1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import cov\n",
    "\n",
    "pressure_cov = cov(data['temp'], data['pressure'])[0][1]\n",
    "wind_cov = cov(data['temp'], data['wind_speed'])[0][1]\n",
    "dew_cov = cov(data['temp'], data['dew_point'])[0][1]\n",
    "humidity_cov = cov(data['temp'], data['humidity'])[0][1]\n",
    "\n",
    "print('temp vs pressure: cov={}'.format(pressure_cov))\n",
    "print('temp vs wind_speed: cov={}'.format(wind_cov))\n",
    "print('temp vs dew_point: cov={}'.format(dew_cov))\n",
    "print('temp vs humidity: cov={}'.format(humidity_cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a better idea of correlations between our features. The higher the covariance factor the higher the correlation. If the covariance is negative then the two features are inversely correlated. We can use all this information to decide which features to select for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing and Modelling\n",
    "\n",
    "Our data is well balanced and is not categorical so there is no need to balance, augment or one-hot-encode it. We'll only be normalising it to have it in a range of `0-1`. For that we'll use the following formula $X_{normalised}=\\frac{X-min(X)}{max(X)-min(X)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Normalise data (min-max normalisation)\n",
    "data = (data - data.min()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split our data into two vectors `X` and `y`. `y` contains the column we want to predict, namely the temperature. `X` contains all the columns (features) we'll use to predict the temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features we use to predict the temperature\n",
    "features = ['humidity', 'pressure', 'dew_point']\n",
    "\n",
    "X = data[features].to_numpy()\n",
    "y = data['temp'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better evaluate our model we separate the data into a training and a testing set. The training set is fed to the model to train and the test set contains data the model has not trained on so we can compute accuracy on unseen data. To achieve this, scikit has the `train_test_split` functions which splits and shuffles the data into 4 partitions for X/y and train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X,\n",
    "  y,\n",
    "  train_size=0.75,\n",
    "  test_size=0.25,\n",
    "  random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally create a linear regression model using the training set and gauge the accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "# Train on training set\n",
    "reg.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Get accuracy on test set\n",
    "reg.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! We now have a handy model to predict temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_William Profit (williamprofit.com) on behalf of ICDSS (icdss.uk)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
